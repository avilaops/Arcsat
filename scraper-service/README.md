# Arcsat Market Intelligence - Guia de IntegraÃ§Ã£o

## ğŸ¯ O que foi criado

Um microserviÃ§o completo de **Market Intelligence** com:
- âœ… Web scraping resiliente (Playwright + stealth)
- âœ… Sistema de filas (Redis)
- âœ… API REST (FastAPI)
- âœ… Suporte a mÃºltiplos marketplaces (Amazon, Mercado Livre)
- âœ… Anti-detecÃ§Ã£o (fingerprinting, proxies rotativos)
- âœ… Docker/docker-compose pronto

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend React â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend Rust   â”‚â—„â”€â”€â”€â”€â–ºâ”‚  PostgreSQL  â”‚
â”‚   (Axum/3000)   â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scraper Service â”‚â—„â”€â”€â”€â”€â–ºâ”‚    Redis     â”‚
â”‚  (Python/8001)  â”‚      â”‚ (Queue/Cache)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Proxies  â”‚
    â”‚(opcional)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Como rodar localmente

### 1. Instalar dependÃªncias do Scraper

```bash
cd scraper-service
python -m venv venv
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
playwright install chromium
```

### 2. Configurar .env

```bash
cp .env.example .env
# Editar .env com suas configuraÃ§Ãµes
```

### 3. Rodar com Docker Compose

```bash
# Na raiz do projeto
docker-compose up -d
```

Isso vai subir:
- Backend Rust (porta 3000)
- Scraper Service (porta 8001)
- PostgreSQL (porta 5432)
- Redis (porta 6379)
- Redis Commander UI (porta 8081)

### 4. Testar o Scraper

```bash
# Criar um job de scraping
curl -X POST http://localhost:8001/api/v1/scraping/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "marketplace": "mercado_livre",
    "search_query": "notebook gamer",
    "max_pages": 3,
    "priority": 5
  }'

# Resposta:
# {
#   "job_id": "uuid-aqui",
#   "status": "pending",
#   "message": "Job criado e adicionado Ã  fila"
# }

# Verificar status
curl http://localhost:8001/api/v1/scraping/jobs/{job_id}
```

## ğŸ”Œ IntegraÃ§Ã£o com o Backend Rust

### Adicionar no seu backend Rust (Axum):

```rust
// Adicionar no Cargo.toml
[dependencies]
reqwest = { version = "0.11", features = ["json"] }

// No seu cÃ³digo Rust
use reqwest::Client;
use serde::{Deserialize, Serialize};

#[derive(Serialize)]
struct ScrapingJobRequest {
    marketplace: String,
    search_query: String,
    max_pages: i32,
    priority: i32,
}

#[derive(Deserialize)]
struct ScrapingJobResponse {
    job_id: String,
    status: String,
    message: String,
}

// Endpoint no Rust que chama o Scraper
async fn create_market_analysis(
    Query(params): Query<MarketAnalysisParams>,
) -> Result<Json<ScrapingJobResponse>, StatusCode> {
    let client = Client::new();

    let job = ScrapingJobRequest {
        marketplace: params.marketplace,
        search_query: params.query,
        max_pages: 5,
        priority: 5,
    };

    let scraper_url = std::env::var("SCRAPER_SERVICE_URL")
        .unwrap_or_else(|_| "http://localhost:8001".to_string());

    let response = client
        .post(format!("{}/api/v1/scraping/jobs", scraper_url))
        .json(&job)
        .send()
        .await
        .map_err(|_| StatusCode::SERVICE_UNAVAILABLE)?;

    let result: ScrapingJobResponse = response
        .json()
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    Ok(Json(result))
}
```

## ğŸ“Š PrÃ³ximos Passos (TODOs)

### Curto Prazo (1-2 semanas)
- [ ] Implementar persistÃªncia no PostgreSQL (models SQLAlchemy)
- [ ] Criar tabelas de migraÃ§Ã£o (Alembic)
- [ ] Adicionar anÃ¡lise de tendÃªncias (pandas/numpy)
- [ ] Implementar sistema de keywords (NLP bÃ¡sico)
- [ ] Criar endpoints no backend Rust

### MÃ©dio Prazo (1 mÃªs)
- [ ] Integrar proxies rotativos (Bright Data/Oxylabs)
- [ ] Implementar resoluÃ§Ã£o de CAPTCHA (2captcha/AntiCaptcha)
- [ ] Criar dashboard no frontend (grÃ¡ficos com Chart.js)
- [ ] Sistema de alertas (produtos em alta)
- [ ] API de histÃ³rico de preÃ§os

### Longo Prazo (2-3 meses)
- [ ] ML para previsÃ£o de tendÃªncias
- [ ] Scraping de mais marketplaces (Shopee, B2W, Magalu)
- [ ] Sistema de recomendaÃ§Ã£o de nichos
- [ ] IntegraÃ§Ã£o com IA (GPT) para anÃ¡lise semÃ¢ntica
- [ ] ExportaÃ§Ã£o de relatÃ³rios (PDF/Excel)

## ğŸ’° Custos Estimados

### Sem proxies (apenas testes locais)
- **Custo:** $0/mÃªs
- **LimitaÃ§Ã£o:** Alto risco de bloqueio, 10-50 requisiÃ§Ãµes/dia

### Com proxies residenciais (produÃ§Ã£o)
- **Bright Data:** ~$500/mÃªs (40GB de dados)
- **Oxylabs:** ~$300/mÃªs (starter plan)
- **Alternativa:** Scraperapi ($49-99/mÃªs, mas menos controle)

### Infraestrutura
- **VPS bÃ¡sica (Hetzner):** â‚¬4.5/mÃªs (2vCPU, 4GB RAM)
- **Railway/Fly.io:** ~$20-50/mÃªs
- **AWS/GCP:** ~$50-100/mÃªs (com auto-scaling)

## âš ï¸ Avisos Legais

1. **Termos de ServiÃ§o:** Scraping viola os ToS da maioria dos marketplaces
2. **Uso ResponsÃ¡vel:**
   - Rate limiting adequado
   - Respeitar robots.txt (ou nÃ£o, sua escolha)
   - NÃ£o causar sobrecarga nos servidores
3. **Risco Legal:**
   - Baixo para usuÃ¡rio final
   - MÃ©dio-Alto para quem opera o serviÃ§o
   - Amazon jÃ¡ processou ferramentas similares

## ğŸ› ï¸ Troubleshooting

### Erro: "Playwright browser not found"
```bash
playwright install chromium
```

### Redis connection refused
```bash
# Verificar se Redis estÃ¡ rodando
docker ps | grep redis
# Ou instalar localmente
# Windows: https://github.com/microsoftarchive/redis/releases
```

### Scraping muito lento
- Reduza `max_pages`
- Aumente `SCRAPER_MAX_CONCURRENT`
- Verifique se proxy estÃ¡ ativo

### CAPTCHAs constantes
- Ative proxies residenciais
- Reduza frequÃªncia de requisiÃ§Ãµes
- Implemente 2captcha/AntiCaptcha

## ğŸ“š DocumentaÃ§Ã£o API

Acesse: http://localhost:8001/docs (Swagger UI automÃ¡tico do FastAPI)

## ğŸ¤ Contribuindo

Este Ã© um sistema complexo. SugestÃµes de melhorias:
- Implementar Celery para filas robustas
- Adicionar testes (pytest)
- Monitoramento (Prometheus + Grafana)
- Logs estruturados (structlog)
- Circuit breaker para resiliÃªncia

---

**Verdade nua e crua:**
- âœ… Tecnicamente viÃ¡vel
- âš ï¸ Legalmente questionÃ¡vel
- ğŸ’° Operacionalmente caro (se escalar)
- ğŸ¯ Comercialmente valioso (se funcionar)
- â° ManutenÃ§Ã£o contÃ­nua necessÃ¡ria (sites mudam)

Boa sorte! ğŸš€
